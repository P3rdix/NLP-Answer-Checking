{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92e2b815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 23:09:38.720084: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-09 23:09:38.722487: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-09 23:09:38.812458: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-09 23:09:39.165706: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-09 23:09:40.172267: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import fasttext\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, LayerNormalization, MultiHeadAttention, Flatten, Add\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eca659c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News Articles</th>\n",
       "      <th>Unlike</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[think, real, danger, happens, data, cross, ne...</td>\n",
       "      <td>[top, gig, award, scissor, sister, new, york, ...</td>\n",
       "      <td>[however, careful, may, organisation, trust, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[fast, moving, phone, virus, appear, security,...</td>\n",
       "      <td>[black, sabbath, top, rock, album, poll, black...</td>\n",
       "      <td>[new, strain, cabir, mobile, phone, virus, use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[seaman, sail, biometric, future, luxury, crui...</td>\n",
       "      <td>[farrell, due, make, u, tv, debut, actor, coli...</td>\n",
       "      <td>[said, french, jordanian, nigerian, national, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[cable, offer, videoondemand, cable, firm, ntl...</td>\n",
       "      <td>[u, firm, bid, lacroix, label, u, firm, said, ...</td>\n",
       "      <td>[cable, firm, ntl, telewest, launched, videoon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[make, greener, computer, hitech, industry, st...</td>\n",
       "      <td>[star, pay, tribute, actor, davis, hollywood, ...</td>\n",
       "      <td>[seeing, thing, technology, industry, result, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>[circuit, city, get, takeover, offer, circuit,...</td>\n",
       "      <td>[saintandre, anger, absent, star, sale, shark,...</td>\n",
       "      <td>[bill, armstrong, retail, analyst, cl, king, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>[german, business, confidence, slide, german, ...</td>\n",
       "      <td>[mcconnell, drunk, remark, row, scotland, firs...</td>\n",
       "      <td>[analyst, said, ifo, figure, germany, continui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>[walmart, fight, back, accuser, two, big, u, n...</td>\n",
       "      <td>[ray, dvd, beat, box, office, taking, oscarnom...</td>\n",
       "      <td>[meanwhile, drug, group, eli, lilly, planning,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>[economy, stronger, forecast, uk, economy, pro...</td>\n",
       "      <td>[whitehall, cut, ahead, target, thousand, civi...</td>\n",
       "      <td>[mpc, judge, overall, growth, little, higher, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>[u, airway, staff, agree, pay, cut, union, rep...</td>\n",
       "      <td>[beattie, return, calm, attack, fear, everton,...</td>\n",
       "      <td>[seventh, largest, carrier, u, sought, bankrup...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          News Articles  \\\n",
       "0     [think, real, danger, happens, data, cross, ne...   \n",
       "1     [fast, moving, phone, virus, appear, security,...   \n",
       "2     [seaman, sail, biometric, future, luxury, crui...   \n",
       "3     [cable, offer, videoondemand, cable, firm, ntl...   \n",
       "4     [make, greener, computer, hitech, industry, st...   \n",
       "...                                                 ...   \n",
       "2220  [circuit, city, get, takeover, offer, circuit,...   \n",
       "2221  [german, business, confidence, slide, german, ...   \n",
       "2222  [walmart, fight, back, accuser, two, big, u, n...   \n",
       "2223  [economy, stronger, forecast, uk, economy, pro...   \n",
       "2224  [u, airway, staff, agree, pay, cut, union, rep...   \n",
       "\n",
       "                                                 Unlike  \\\n",
       "0     [top, gig, award, scissor, sister, new, york, ...   \n",
       "1     [black, sabbath, top, rock, album, poll, black...   \n",
       "2     [farrell, due, make, u, tv, debut, actor, coli...   \n",
       "3     [u, firm, bid, lacroix, label, u, firm, said, ...   \n",
       "4     [star, pay, tribute, actor, davis, hollywood, ...   \n",
       "...                                                 ...   \n",
       "2220  [saintandre, anger, absent, star, sale, shark,...   \n",
       "2221  [mcconnell, drunk, remark, row, scotland, firs...   \n",
       "2222  [ray, dvd, beat, box, office, taking, oscarnom...   \n",
       "2223  [whitehall, cut, ahead, target, thousand, civi...   \n",
       "2224  [beattie, return, calm, attack, fear, everton,...   \n",
       "\n",
       "                                                Summary  \n",
       "0     [however, careful, may, organisation, trust, p...  \n",
       "1     [new, strain, cabir, mobile, phone, virus, use...  \n",
       "2     [said, french, jordanian, nigerian, national, ...  \n",
       "3     [cable, firm, ntl, telewest, launched, videoon...  \n",
       "4     [seeing, thing, technology, industry, result, ...  \n",
       "...                                                 ...  \n",
       "2220  [bill, armstrong, retail, analyst, cl, king, a...  \n",
       "2221  [analyst, said, ifo, figure, germany, continui...  \n",
       "2222  [meanwhile, drug, group, eli, lilly, planning,...  \n",
       "2223  [mpc, judge, overall, growth, little, higher, ...  \n",
       "2224  [seventh, largest, carrier, u, sought, bankrup...  \n",
       "\n",
       "[2225 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"preprocessed_data.csv\")\n",
    "data.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "\n",
    "def revert(sentence):\n",
    "    x = sentence.split(\"^\")\n",
    "    return [i.split(\"%\") for i in x]\n",
    "\n",
    "def flatten(text):\n",
    "    x = []\n",
    "    for sentence in text:\n",
    "        x += sentence\n",
    "    return x\n",
    "\n",
    "data[\"News Articles\"] = data[\"News Articles\"].apply(revert)\n",
    "data[\"Summary\"] = data[\"Summary\"].apply(revert)\n",
    "data[\"Unlike\"] = data[\"Unlike\"].apply(revert)\n",
    "\n",
    "data[\"News Articles\"] = data[\"News Articles\"].apply(flatten)\n",
    "data[\"Summary\"] = data[\"Summary\"].apply(flatten)\n",
    "data[\"Unlike\"] = data[\"Unlike\"].apply(flatten)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b62a431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext_training(tmp):\n",
    "    model_type = \"skipgram\"\n",
    "    x = \"\"\n",
    "    for i in [\"News Articles\", \"Summary\",\"Unlike\"]:\n",
    "        s = []\n",
    "        for j in tmp[i]:\n",
    "            s.append(\" \".join(j))\n",
    "        x += \" \".join(s)\n",
    "    with open(\"fastext_data.txt\",\"w\") as f:\n",
    "        f.write(x)\n",
    "    return fasttext.train_unsupervised('fastext_data.txt', model=model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eab9875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 1M words\n",
      "Number of words:  16842\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:   24102 lr:  0.000000 avg.loss:  2.001978 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "embedding_model = fasttext_training(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed794d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2440"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = 0\n",
    "c = \"\"\n",
    "for i in data.columns:\n",
    "    for j in data[i]:\n",
    "        if f<len(j):\n",
    "            f = len(j)\n",
    "            c = j\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84fb435a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_words(sentence):\n",
    "    l = 2440\n",
    "    n = [\"_\" for i in range(l-len(sentence))]\n",
    "    if sentence == []:\n",
    "        return n\n",
    "    return n[:len(n)//2] + sentence + n[len(n)//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d25b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"P News Articles\"] = data[\"News Articles\"].apply(pad_words)\n",
    "data[\"P Summary\"] = data[\"Summary\"].apply(pad_words)\n",
    "data[\"P Unlike\"] = data[\"Unlike\"].apply(pad_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84d2ef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(text):\n",
    "    embedding = []\n",
    "    for i in text:\n",
    "        embedding.append(embedding_model[i])\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb25fbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"E News Articles\"] = data[\"P News Articles\"].apply(embed)\n",
    "data[\"E Summary\"] = data[\"P Summary\"].apply(embed)\n",
    "data[\"E Unlike\"] = data[\"P Unlike\"].apply(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f11804b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([i for i in data.columns if i[0]!=\"E\"], axis=1, inplace=True)\n",
    "data = data[data.columns][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f57ea471",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(data[\"E News Articles\"])):\n",
    "    x.append(data[\"E News Articles\"][i])\n",
    "    y.append(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02d660f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98b09285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2440, 100)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.asarray(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65fc208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "202f08fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr,xt,ytr,yt = train_test_split(x,y,test_size=0.3,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f077035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inp = Input(shape=(2440,100))\n",
    "\n",
    "x = Dense(1220,activation=\"relu\")(inp)\n",
    "x = Dense(610,activation=\"relu\")(x)\n",
    "x = Dense(303,activation=\"relu\")(x)\n",
    "x = Dense(128,activation=\"tanh\")(x)\n",
    "x = Dense(303,activation=\"tanh\")(x)\n",
    "x = Dense(610,activation=\"tanh\")(x)\n",
    "x = Dense(1220,activation=\"tanh\")(x)\n",
    "\n",
    "a1 = Model(inp, x)\n",
    "a2 = Model(inp, x)\n",
    "\n",
    "inputs = Input(shape=(128, 2))\n",
    "x = inputs\n",
    "\n",
    "for _ in range(3):\n",
    "    # Transformer Block with multi-head attention\n",
    "    query = LayerNormalization(epsilon=1e-6)(x)\n",
    "    key = LayerNormalization(epsilon=1e-6)(x)\n",
    "    value = LayerNormalization(epsilon=1e-6)(x)\n",
    "\n",
    "    attn_output = MultiHeadAttention(num_heads=4, key_dim=256, dropout=0.3)(query, value, key=key)\n",
    "    x = Add()([x, attn_output])  # Residual connection\n",
    "    x = LayerNormalization(epsilon=1e-6)(x)\n",
    "\n",
    "    # Feed Forward Network inside transformer\n",
    "\n",
    "    ffn_output = Dense(128, activation=\"relu\")(x)\n",
    "    ffn_output = Dropout(0.3)(ffn_output)\n",
    "    ffn_output = Dense(64, activation=\"relu\")(ffn_output)\n",
    "    ffn_output = Dense(1)(ffn_output)\n",
    "    x = Add()([x, ffn_output])  # Residual connection\n",
    "    x = LayerNormalization(epsilon=1e-6)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "outputs = Dense(1)(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a704bb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1.compile(loss=\"mean_squared_error\", optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "a2.compile(loss=\"mean_squared_error\", optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "503e76e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=10)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.2, patience=5, min_lr=0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfe8cf9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 100 and 1220 for '{{node compile_loss/mean_squared_error/sub}} = Sub[T=DT_FLOAT](data_1, functional_7_1/dense_23_1/Tanh)' with input shapes: [4,2440,100], [4,2440,1220].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6320/909849306.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     a1.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mxtr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mxtr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/losses/losses.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqueeze_or_expand_to_same_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 100 and 1220 for '{{node compile_loss/mean_squared_error/sub}} = Sub[T=DT_FLOAT](data_1, functional_7_1/dense_23_1/Tanh)' with input shapes: [4,2440,100], [4,2440,1220]."
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    a1.fit(\n",
    "        xtr,\n",
    "        xtr,\n",
    "        epochs=100,\n",
    "        batch_size=4,\n",
    "        validation_split=0.2,\n",
    "        verbose=1,\n",
    "        callbacks=[es, reduce_lr],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2971425",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
